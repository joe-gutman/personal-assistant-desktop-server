import json
import base64
import logging
from datetime import datetime
from .schemas import AudioContent, Message, MessageType, AudioStatus, Source
from src.extensions import STTClient, AIClient , TTSClient

logger = logging.getLogger(__name__)

class CommunicationService:
    def __init__(self):
        self.ws = None

        # Load configs once
        with open("config/ai.json", "r", encoding="utf-8") as f:
            ai_config = json.load(f)
        with open("config/models.json", "r", encoding="utf-8") as f:
            models_config = json.load(f)

        prompts = ai_config["prompts"]
        self.ai = AIClient(
            name=ai_config.get("name", "Ava"),
            activation_prompt=prompts["activation"],
            intent_prompt=prompts["intent"],
            command_prompt=prompts["command"],
            response_prompt=prompts["response"]
        )
        self.stt = STTClient(on_transcript=self.on_transcript)  # You can pass config if needed
        # Pass voice config section to TTSClient
        voice_name = ai_config.get("voice", {}).get("name", "emma")
        self.tts = TTSClient(voice_name=voice_name, on_speach=self.on_speach, voices_config=models_config.get("voices", {}))

        logger.debug("CommunicationService initialized.")

    def register_websocket(self, websocket):
        self.ws = websocket

    async def process_client_message(self, raw_message):
        if not self.ws:
            logger.warning("No WebSocket registered.")
            return

        try:
            data = json.loads(raw_message)
            msg = Message.model_validate(data)
            content = msg.content
            
            if msg.type == MessageType.AUDIO and msg.source == Source.CLIENT:
                if content.status == AudioStatus.LISTENING:
                    if not self.stt.status:
                        await self.stt.start_listening()
                    if content.audio:
                        audio_data = base64.b64decode(content.audio)
                        self.stt.transcribe_audio(audio_data)
                elif content.status == AudioStatus.STOPPED:
                    if self.stt.status:
                        await self.stt.stop_listening()
                        
        except Exception as e:
            await self.ws.send(f"Error processing message: {e}")
            logger.error(f"Error processing message: {e}", exc_info=True)
            

    async def on_transcript(self, text):
        if not self.ws:
            logger.warning("No output WebSocket registered.")
            return

        try:
            ai_response = self.ai.handle_user_input(text)
            if not ai_response:
                logger.info("No response generated by AI.")
                return
            else:
                logger.info(f"AI response: {ai_response}")
            await self.tts.speak(ai_response)
        except Exception as e:
            logger.error(f"WebSocket send error: {e}", exc_info=True)
            
    async def on_speach(self, audio_data):
        if not self.ws:
            logger.warning("No output WebSocket registered.")
            return

        try:
            logger.debug(f"Processing audio chunk, type: {type(audio_data)}")
            audio_bytes = audio_data.audio_int16_bytes
            
            # Split large audio chunks into smaller pieces (e.g., 4KB chunks)
            chunk_size = 4096  # 4KB chunks
            for i in range(0, len(audio_bytes), chunk_size):
                chunk = audio_bytes[i:i + chunk_size]
                audio_base64 = base64.b64encode(chunk).decode('utf-8')
                
                response = Message(
                    source=Source.SERVER,
                    type=MessageType.AUDIO,
                    source_id=None,
                    target_id=None,
                    timestamp=datetime.now().isoformat(), 
                    content=AudioContent(
                        status=AudioStatus.SPEAKING,
                        audio=audio_base64
                    )
                )
                
                if Message.model_validate(response):
                    debug_msg = response.model_dump()
                    debug_msg["content"]["audio"] = debug_msg["content"]["audio"][:10] + "..."
                    logger.debug(f"Sending TTS audio chunk {i//chunk_size + 1}: " + str(debug_msg))
                    await self.ws.send(response.model_dump_json())
                    logger.debug(f"Successfully sent audio chunk {i//chunk_size + 1}")
                else:
                    logger.error("Invalid message schema.")
        except Exception as e:
            logger.error(f"WebSocket send error: {e}", exc_info=True)


communication_service = CommunicationService()
