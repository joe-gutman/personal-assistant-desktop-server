import json
import base64
import logging
from datetime import datetime
from .schemas import AudioContent, Message, MessageType, AudioStatus, Source
from src.extensions import STTClient, AIClient , TTSClient

logger = logging.getLogger(__name__)

class CommunicationService:
    def __init__(self):
        self.ws = None

        self.ai = AIClient()
        self.stt = STTClient(on_transcript=self.on_transcript)
        self.tts = TTSClient(on_speach=self.on_speach)  # Placeholder for TTSClient

        logger.debug("CommunicationService initialized.")

    def register_websocket(self, websocket):
        self.ws = websocket

    async def process_client_message(self, raw_message):
        if not self.ws:
            logger.warning("No WebSocket registered.")
            return

        try:
            data = json.loads(raw_message)
            msg = Message.model_validate(data)
            content = msg.content
            
            if msg.type == MessageType.AUDIO and msg.source == Source.CLIENT:
                if content.status == AudioStatus.LISTENING:
                    if not self.stt.status:
                        await self.stt.start_listening()
                    if content.audio:
                        audio_data = base64.b64decode(content.audio)
                        self.stt.transcribe_audio(audio_data)
                elif content.status == AudioStatus.STOPPED:
                    if self.stt.status:
                        await self.stt.stop_listening()
                        
        except Exception as e:
            await self.ws.send(f"Error processing message: {e}")
            logger.error(f"Error processing message: {e}", exc_info=True)
            

    async def on_transcript(self, text):
        if not self.ws:
            logger.warning("No output WebSocket registered.")
            return

        try:
            ai_response = self.ai.handle_user_input(text)
            if not ai_response:
                logger.info("No response generated by AI.")
                return
            else:
                logger.info(f"AI response: {ai_response}")
            await self.tts.speak(ai_response)
        except Exception as e:
            logger.error(f"WebSocket send error: {e}", exc_info=True)
            
    async def on_speach(self, audio_data):
        if not self.ws:
            logger.warning("No output WebSocket registered.")
            return

        try:
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            response = Message(
                source=Source.SERVER,
                type=MessageType.AUDIO,
                source_id=None,
                target_id=None,
                timestamp=datetime.now().isoformat(), 
                content=AudioContent(
                    status=AudioStatus.SPEAKING,
                    audio=audio_base64
                )
            )
            
            if Message.model_validate(response):
                debug_msg = response.model_dump()
                debug_msg["content"]["audio"] = debug_msg["content"]["audio"][:10] + "..."
                logger.debug("Sending TTS audio chunk: " + str(debug_msg))
                await self.ws.send(response.model_dump_json())
            else:
                logger.error("Invalid message schema.")
        except Exception as e:
            logger.error(f"WebSocket send error: {e}", exc_info=True)


communication_service = CommunicationService()
